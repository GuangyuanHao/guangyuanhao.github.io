---
layout: page
---

# About Me

<img src="https://guangyuanhao.github.io/guangyuan1.jpg" class="floatpic" width="1200" height="800">

<!-- I am Guangyuan Hao, currently serving as a research assistant with a focus on causality, physically in Abu Dhabi. My research is conducted under the guidance of esteemed professors [Kun Zhang](https://www.andrew.cmu.edu/user/kunz1/) at Carnegie Mellon University (CMU) and [Jiji Zhang](https://arts.cuhk.edu.hk/web/index.php/professor-zhang-jiji) at The Chinese University of Hong Kong (CUHK).

Additionally, since 2020, I have had the privilege of closely collaborating with Professor [Hao Wang](http://www.wanghao.in/) at Rutgers University, specifically in the field of Safe /Trustworthy AI. -->

Hi, I am Guangyuan Hao, a researcher dedicated to developing AI technologies that positively impact society. I am now working on the theoretical foundations of multimodal learning under Prof. Paul Liang at MIT.

<br>

I recently joined the [ML Alignment & Theory Scholars (MATS) Program](https://www.matsprogram.org) at Berkeley for a ten-week period, where I worked on AI safety research and participated in talks and workshops within the Berkeley alignment research community.
 
 <!-- My research is focusing on AI Safety, especially for LLMs, under the guidance of [Dr. Steven Basart](https://stevenbas.art/) at Center for AI Safety. -->

<!-- Additionally, since 2021, I have had the privilege of closely collaborating with Professor [Hao Wang](http://www.wanghao.in/) at Rutgers University, specifically in the field of Safe /Trustworthy AI. -->

<!-- Furthermore, I am engaged in collaborative research endeavors with Professors [Yuanzhi Li](https://scholar.google.com/citations?user=aHtfItQAAAAJ&hl=en) and Kun Zhang at CMU, exploring the fascinating realm of the physics of Large Language Models (LLMs) recently. -->

<br>

I graduated from the Hong Kong University of Science and Technology with an MPhil, where my research focused on AI Safety, particularly in the areas of robustness and interpretability, advised by Professors [Dit-Yan Yeung (HKUST)](https://sites.google.com/view/dyyeung) and [Hao Wang (Rutgers)](http://www.wanghao.in/). My recent work has aimed to establish theoretical guarantees and develop methods to improve out-of-distribution (OOD) generalization and robustness. Driven by a deep interest in interpretability, I have spent over a year studying causality, working closely under the guidance of renowned professors [Jiji Zhang (CUHK)](https://arts.cuhk.edu.hk/web/index.php/professor-zhang-jiji) and [Kun Zhang (CMU)](https://www.andrew.cmu.edu/user/kunz1/).

Email-* guangyuan.hao[at]connect[dot]ust[dot]hk*

<br>

---

***News and Updates***

- **Sept 25th, 2024:** A first-author paper has been accepted to NeurIPS 2024, proposing a new theoretical framework for counterfactual inference grounded in the philosophical perspective of backtracking counterfactuals.
- **June 15th, 2024:** Starting a journey at Berkeley for MATS program.

<!-- - **Dec 2023:** I just started a new exciting project on the physics of LLMs. -->

<br>

---

## Research Interests

- **Safe and trustworthy AI**: Emphasis on robustness, including out-of-distribution generalization, and interpretability, such as causal reasoning.
- **Multisensory Intelligence**: Exploration of both theoretical and practical approaches to understanding and utilizing multisensory data, with applications in areas like healthcare and AI safety.




<!-- - Physics of LLMs -->


<!-- My primary focus revolves around the development of theoretical frameworks aimed at explaining data and AI models and address real-world challenges to make AI systems trustworthy. -->



<!-- I am deeply dedicated to the field of causality, which plays a pivotal role in uncovering and comprehending cause-and-effect relationships. Causality inherently provides interpretability and robustness while enabling evidence-based decision-making. My ultimate goal is to extend the applicability of causality to deal with complex real-world data, such as images, texts, and videos.

Furthermore, I am fully immersed in the exploration of the Physics of Large Language Models (LLMs). My goal is to unravel the emergence of intelligence within these LLMs and potentially formulate corresponding theories. This endeavor aims to elevate the intelligence of Artificial General Intelligence (AGI) and mitigate the risk of its misuse.

I firmly believe that substantial theoretical advancements are driven by real-world applications. My specific focus revolves around harnessing the combined power of causality and LLMs for applications in trustworthy AI and groundbreaking scientific domains, including automated theorem proving, protein research, materials discovery, and more. These domains are pivotal in identifying urgent challenges and unlocking the untapped potential inherent in causality and the physics of LLMs. -->

<br>

---
## Academic Background
<!-- **<font color='red'>[Highlight]</font> I am looking for PhD to start in 2025 Fall. Contact me if you have any leads!** -->

- **Sep. 2020 - Sep. 2022:** Hong Kong University of Science and Technology, Master of Philosophy (MPhil) in Individualized Interdisciplinary Program (Artificial Intelligence); Awarded a full scholarship
- **Sep. 2012 - July 2016:** University of Electronic Science and Technology of China, Bachelor of Engineering (B.E.) in Information Display and Optoelectronic Technology; Ranking 1st/184

<br>



